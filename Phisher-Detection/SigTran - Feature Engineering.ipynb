{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHnJ75C55NvE",
        "outputId": "ae827df1-cb0f-4742-a4b7-5713f34dfc37"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4SyilK-XJp3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3de64a27-db43-458f-9579-664f185258c3"
      },
      "source": [
        "\"\"\"\n",
        "Specify the inclusion of the features in the experiments\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "\n",
        "class FeatureStatus:\n",
        "    def __init__(self):\n",
        "        self.feature_stat = self.generate_feature_status()\n",
        "\n",
        "    def generate_feature_status(self):\n",
        "        \"\"\"\"\n",
        "        generate the status of different features\n",
        "        \"\"\"\n",
        "        feature_df_column_name = ['feature', 'select']\n",
        "        feature_dict = {\n",
        "            # major features\n",
        "            0: ['node', 1],\n",
        "\n",
        "            # 1: ['address', 0],  # NEVER select\n",
        "            2: ['isp', 0],  # NEVER select\n",
        "            # 3: ['is_anchor', 0],  # NEVER select\n",
        "\n",
        "            5: ['degree', 0],\n",
        "            6: ['in_degree', 1],  # this\n",
        "            7: ['out_degree', 0],\n",
        "\n",
        "            8: ['avg_amount_in_tx', 0],\n",
        "            9: ['min_amount_in_tx', 0],\n",
        "            10: ['max_amount_in_tx', 0],\n",
        "            11: ['sum_amount_in_tx', 1],  # this\n",
        "            12: ['std_amount_in_tx', 1],  # this\n",
        "            13: ['ent_amount_in_tx', 0],\n",
        "\n",
        "            14: ['avg_in_tx_interval', 1],  # this\n",
        "            15: ['min_in_tx_interval', 0],\n",
        "            16: ['max_in_tx_interval', 1],  # this\n",
        "            17: ['sum_in_tx_interval', 1],  # this\n",
        "            18: ['std_in_tx_interval', 0],\n",
        "            19: ['ent_in_tx_interval', 0],\n",
        "\n",
        "            20: ['avg_amount_out_tx', 0],\n",
        "            21: ['min_amount_out_tx', 0],\n",
        "            22: ['max_amount_out_tx', 0],\n",
        "            23: ['sum_amount_out_tx', 1],  # this\n",
        "            24: ['std_amount_out_tx', 0],\n",
        "            25: ['ent_amount_out_tx', 0],\n",
        "\n",
        "            26: ['avg_out_tx_interval', 0],\n",
        "            27: ['min_out_tx_interval', 0],\n",
        "            28: ['max_out_tx_interval', 0],\n",
        "            29: ['sum_out_tx_interval', 0],\n",
        "            30: ['std_out_tx_interval', 0],\n",
        "            31: ['ent_out_tx_interval', 0],\n",
        "\n",
        "            32: ['avg_amount_all_tx', 0],\n",
        "            33: ['min_amount_all_tx', 0],\n",
        "            34: ['max_amount_all_tx', 0],\n",
        "            35: ['sum_amount_all_tx', 0],\n",
        "            36: ['std_amount_all_tx', 0],\n",
        "            37: ['ent_amount_all_tx', 1],  # this\n",
        "\n",
        "            38: ['avg_all_tx_interval', 0],\n",
        "            39: ['min_all_tx_interval', 0],\n",
        "            40: ['max_all_tx_interval', 0],\n",
        "            41: ['sum_all_tx_interval', 0],\n",
        "            42: ['std_all_tx_interval', 0],\n",
        "            43: ['ent_all_tx_interval', 0],\n",
        "\n",
        "            44: ['no_edge_within_egonet', 0],\n",
        "            45: ['no_edge_in_egonet', 1],  # this\n",
        "            46: ['no_edge_out_egonet', 0],\n",
        "            47: ['no_edge_all_egonet', 1],  # this\n",
        "\n",
        "            48: ['avg_neighbor_degree', 0],\n",
        "            49: ['min_neighbor_degree', 0],\n",
        "            50: ['max_neighbor_degree', 0],\n",
        "            51: ['sum_neighbor_degree', 0],\n",
        "            52: ['std_neighbor_degree', 0],\n",
        "            53: ['ent_neighbor_degree', 0],\n",
        "\n",
        "            54: ['avg_neighbor_w_degree', 0],\n",
        "            55: ['min_neighbor_w_degree', 0],\n",
        "            56: ['max_neighbor_w_degree', 0],\n",
        "            57: ['sum_neighbor_w_degree', 0],\n",
        "            58: ['std_neighbor_w_degree', 0],\n",
        "            59: ['ent_neighbor_w_degree', 0],\n",
        "\n",
        "            60: ['avg_neighbor_in_degree', 0],\n",
        "            61: ['min_neighbor_in_degree', 0],\n",
        "            62: ['max_neighbor_in_degree', 0],\n",
        "            63: ['sum_neighbor_in_degree', 0],\n",
        "            64: ['std_neighbor_in_degree', 0],\n",
        "            65: ['ent_neighbor_in_degree', 0],\n",
        "\n",
        "            66: ['avg_neighbor_out_degree', 0],\n",
        "            67: ['min_neighbor_out_degree', 0],\n",
        "            68: ['max_neighbor_out_degree', 0],\n",
        "            69: ['sum_neighbor_out_degree', 0],\n",
        "            70: ['std_neighbor_out_degree', 0],\n",
        "            71: ['ent_neighbor_out_degree', 0],\n",
        "\n",
        "            # 62: ['balance', 1, 0],\n",
        "\n",
        "            # derived features\n",
        "        }\n",
        "\n",
        "        feature_df = pd.DataFrame.from_dict(feature_dict, orient='index',\n",
        "                                            columns=feature_df_column_name)\n",
        "\n",
        "        return feature_df\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    check functionality\n",
        "    \"\"\"\n",
        "    feature_st = FeatureStatus()\n",
        "    print(feature_st.feature_stat.head())\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      feature  select\n",
            "0        node       1\n",
            "2         isp       0\n",
            "5      degree       0\n",
            "6   in_degree       1\n",
            "7  out_degree       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNuWzJvxXM9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaa18e69-bc85-4370-eb81-9395a18bbfa9"
      },
      "source": [
        "\"\"\"\n",
        "generate the designated features for the nodes of the graph\n",
        "\"\"\"\n",
        "import datetime\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "from scipy.stats import entropy\n",
        "\n",
        "class NodeEngFeatures:\n",
        "    def __init__(self, nodes, edges):\n",
        "        self.nodes = nodes  # a dataframe\n",
        "        self.edges = edges  # a dataframe\n",
        "        self.G = nx.from_pandas_edgelist(self.edges, source='source', target='target',\n",
        "                                         edge_attr=['timestamp', 'amount'],\n",
        "                                         create_using=nx.MultiDiGraph())\n",
        "        print(\"*** Original MD-Graph ***\")\n",
        "        print(nx.info(self.G))\n",
        "        self.node_feature_names = self.retrieve_feature_name()\n",
        "\n",
        "    def retrieve_feature_name(self):\n",
        "        \"\"\"\n",
        "        retrieve the names of the features for the nodes\n",
        "        \"\"\"\n",
        "        feature_stat_df = FeatureStatus().feature_stat\n",
        "        feature_name_list = feature_stat_df['feature'].tolist()\n",
        "        return feature_name_list\n",
        "\n",
        "    def get_tx_amount_and_interval_list(self, node, opt):\n",
        "        \"\"\"\n",
        "        returns the list of amount and the list of timestamps for all the (opt-) transactions\n",
        "        :param node: the node that we focus on\n",
        "        :param opt: 'in', 'out', or 'all' transactions\n",
        "        \"\"\"\n",
        "        if opt == 'in':  # incoming tx\n",
        "            node_tx_df = self.edges[self.edges['target'] == node]\n",
        "        elif opt == 'out':  # outgoing tx\n",
        "            node_tx_df = self.edges[self.edges['source'] == node]\n",
        "        elif opt == 'all':  # all tx\n",
        "            node_tx_df = self.edges[(self.edges['target'] == node) | (self.edges['source'] == node)]\n",
        "        else:\n",
        "            raise ValueError(\"Option unavailable!\")\n",
        "\n",
        "        amount_list = node_tx_df['amount'].tolist()\n",
        "        linux_timestamp_list = node_tx_df['timestamp'].tolist()\n",
        "        timestamp_list = [datetime.datetime.fromtimestamp(t) for t in linux_timestamp_list]\n",
        "        timestamp_list.sort()\n",
        "        # interval of txs in minutes\n",
        "        tx_interval = [((timestamp_list[i + 1] - timestamp_list[i]).total_seconds() / 60) for i\n",
        "                       in range(len(timestamp_list) - 1)]\n",
        "\n",
        "        return amount_list, tx_interval\n",
        "\n",
        "    def neighbor_degree_features(self, node):\n",
        "        \"\"\"\n",
        "        get the features related to the degree distributions of the neighbors of the node\n",
        "        \"\"\"\n",
        "        # extract the egonet of the node\n",
        "        egonet = nx.ego_graph(self.G, node)\n",
        "\n",
        "        # prerequisite for some neighborhood features\n",
        "        egonet_node = nx.nodes(egonet)\n",
        "        no_edge_egonet_in = 0  # number of in-coming edges to egonet\n",
        "        no_edge_egonet_out = 0  # number of out-going edges from egonet\n",
        "        for nb_node in egonet_node:\n",
        "            if node != nb_node:\n",
        "                no_edge_egonet_in += (self.G.in_degree[nb_node] - egonet.in_degree[nb_node])\n",
        "                no_edge_egonet_out += (self.G.out_degree[nb_node] - egonet.out_degree[nb_node])\n",
        "\n",
        "        neighbor_degrees = [d for n, d in egonet.degree() if n != node]\n",
        "        neighbor_w_degrees = [d for n, d in egonet.degree(weight='amount') if n != node]\n",
        "        neighbor_in_degrees = [d for n, d in egonet.in_degree() if n != node]\n",
        "        neighbor_out_degrees = [d for n, d in egonet.out_degree() if n != node]\n",
        "\n",
        "        no_edge_egonet = egonet.number_of_edges()\n",
        "\n",
        "        return no_edge_egonet, no_edge_egonet_in, no_edge_egonet_out, \\\n",
        "               neighbor_degrees, neighbor_w_degrees, neighbor_in_degrees, neighbor_out_degrees\n",
        "\n",
        "    def gen_node_features_single(self, node):\n",
        "        \"\"\"\n",
        "        generate the features for the node\n",
        "        :param node: node of interest\n",
        "        \"\"\"\n",
        "        no_edge_egonet, no_edge_egonet_in, no_edge_egonet_out, \\\n",
        "            neighbor_degrees, neighbor_w_degrees, neighbor_in_degrees, neighbor_out_degrees = \\\n",
        "            self.neighbor_degree_features(node)\n",
        "        amnt_in_list, interval_in_tx = self.get_tx_amount_and_interval_list(node, 'in')\n",
        "        amnt_out_list, interval_out_tx = self.get_tx_amount_and_interval_list(node, 'out')\n",
        "        amnt_all_list, interval_all_tx = self.get_tx_amount_and_interval_list(node, 'all')\n",
        "        node_row = self.nodes.loc[self.nodes['node'] == node]\n",
        "        node_feature_dict = {\n",
        "            'node': node_row['node'].values[0],\n",
        "            # 'address': node_row['address'].values[0],\n",
        "            'isp': node_row['isp'].values[0],\n",
        "            # 'is_anchor': node_row['is_anchor'].values[0],\n",
        "            # 'balance': node_row['balance'].values[0],\n",
        "\n",
        "            # structural\n",
        "            'degree': len(amnt_all_list),\n",
        "            # 'w_degree': self.G.degree(node, weight='amount'),\n",
        "            'in_degree': len(amnt_in_list),\n",
        "            'out_degree': len(amnt_out_list),\n",
        "\n",
        "            # transactional\n",
        "            'avg_amount_in_tx': np.mean(amnt_in_list) if len(amnt_in_list) > 0 else 0,\n",
        "            'min_amount_in_tx': np.min(amnt_in_list) if len(amnt_in_list) > 0 else 0,\n",
        "            'max_amount_in_tx': np.max(amnt_in_list) if len(amnt_in_list) > 0 else 0,\n",
        "            'sum_amount_in_tx': np.sum(amnt_in_list),\n",
        "            'std_amount_in_tx': np.std(amnt_in_list) if len(amnt_in_list) > 0 else 0,\n",
        "            'ent_amount_in_tx': entropy(amnt_in_list) if np.sum(amnt_in_list) != 0 else 0,\n",
        "\n",
        "            'avg_in_tx_interval': np.mean(interval_in_tx) if len(interval_in_tx) > 0 else 0,\n",
        "            'min_in_tx_interval': np.min(interval_in_tx) if len(interval_in_tx) > 0 else 0,\n",
        "            'max_in_tx_interval': np.max(interval_in_tx) if len(interval_in_tx) > 0 else 0,\n",
        "            'sum_in_tx_interval': np.sum(interval_in_tx),\n",
        "            'std_in_tx_interval': np.std(interval_in_tx) if len(interval_in_tx) > 0 else 0,\n",
        "            'ent_in_tx_interval': entropy(interval_in_tx) if np.sum(interval_in_tx) != 0 else 0,\n",
        "\n",
        "            'avg_amount_out_tx': np.mean(amnt_out_list) if len(amnt_out_list) > 0 else 0,\n",
        "            'min_amount_out_tx': np.min(amnt_out_list) if len(amnt_out_list) > 0 else 0,\n",
        "            'max_amount_out_tx': np.max(amnt_out_list) if len(amnt_out_list) > 0 else 0,\n",
        "            'sum_amount_out_tx': np.sum(amnt_out_list),\n",
        "            'std_amount_out_tx': np.std(amnt_out_list) if len(amnt_out_list) > 0 else 0,\n",
        "            'ent_amount_out_tx': entropy(amnt_out_list) if np.sum(amnt_out_list) != 0 else 0,\n",
        "\n",
        "            'avg_out_tx_interval': np.mean(interval_out_tx) if len(interval_out_tx) > 0 else 0,\n",
        "            'min_out_tx_interval': np.min(interval_out_tx) if len(interval_out_tx) > 0 else 0,\n",
        "            'max_out_tx_interval': np.max(interval_out_tx) if len(interval_out_tx) > 0 else 0,\n",
        "            'sum_out_tx_interval': np.sum(interval_out_tx),\n",
        "            'std_out_tx_interval': np.std(interval_out_tx) if len(interval_out_tx) > 0 else 0,\n",
        "            'ent_out_tx_interval': entropy(interval_out_tx) if np.sum(interval_out_tx) != 0 else 0,\n",
        "\n",
        "            'avg_amount_all_tx': np.mean(amnt_all_list) if len(amnt_all_list) > 0 else 0,  # all tx: in & out\n",
        "            'min_amount_all_tx': np.min(amnt_all_list) if len(amnt_all_list) > 0 else 0,\n",
        "            'max_amount_all_tx': np.max(amnt_all_list) if len(amnt_all_list) > 0 else 0,\n",
        "            'sum_amount_all_tx': np.sum(amnt_all_list),  # this should be equal to weighted degree\n",
        "            'std_amount_all_tx': np.std(amnt_all_list) if len(amnt_all_list) > 0 else 0,\n",
        "            'ent_amount_all_tx': entropy(amnt_all_list) if np.sum(amnt_all_list) != 0 else 0,\n",
        "\n",
        "            'avg_all_tx_interval': np.mean(interval_all_tx) if len(interval_all_tx) > 0 else 0,\n",
        "            'min_all_tx_interval': np.min(interval_all_tx) if len(interval_all_tx) > 0 else 0,\n",
        "            'max_all_tx_interval': np.max(interval_all_tx) if len(interval_all_tx) > 0 else 0,\n",
        "            'sum_all_tx_interval': np.sum(interval_all_tx),\n",
        "            'std_all_tx_interval': np.std(interval_all_tx) if len(interval_all_tx) > 0 else 0,\n",
        "            'ent_all_tx_interval': entropy(interval_all_tx) if np.sum(interval_all_tx) != 0 else 0,\n",
        "\n",
        "            # regional features\n",
        "            'no_edge_within_egonet': no_edge_egonet,  # number of edges within the egonet for all nodes\n",
        "            'no_edge_in_egonet': no_edge_egonet_in,  # number of in-edges to the egonet\n",
        "            'no_edge_out_egonet': no_edge_egonet_out,  # number of out-edges from the egonet\n",
        "            'no_edge_all_egonet': no_edge_egonet_in + no_edge_egonet_out,  # total number of edges to/from the egonet\n",
        "\n",
        "            # neighborhood features\n",
        "            'avg_neighbor_degree': np.mean(neighbor_degrees) if len(neighbor_degrees) > 0 else 0,\n",
        "            'min_neighbor_degree': np.min(neighbor_degrees) if len(neighbor_degrees) > 0 else 0,\n",
        "            'max_neighbor_degree': np.max(neighbor_degrees) if len(neighbor_degrees) > 0 else 0,\n",
        "            'sum_neighbor_degree': np.sum(neighbor_degrees),\n",
        "            'std_neighbor_degree': np.std(neighbor_degrees) if len(neighbor_degrees) > 0 else 0,\n",
        "            'ent_neighbor_degree': entropy(neighbor_degrees) if np.sum(neighbor_degrees) != 0 else 0,\n",
        "\n",
        "            'avg_neighbor_w_degree': np.mean(neighbor_w_degrees) if len(neighbor_w_degrees) > 0 else 0,\n",
        "            'min_neighbor_w_degree': np.min(neighbor_w_degrees) if len(neighbor_w_degrees) > 0 else 0,\n",
        "            'max_neighbor_w_degree': np.max(neighbor_w_degrees) if len(neighbor_w_degrees) > 0 else 0,\n",
        "            'sum_neighbor_w_degree': np.sum(neighbor_w_degrees),\n",
        "            'std_neighbor_w_degree': np.std(neighbor_w_degrees) if len(neighbor_w_degrees) > 0 else 0,\n",
        "            'ent_neighbor_w_degree': entropy(neighbor_w_degrees) if np.sum(neighbor_w_degrees) != 0 else 0,\n",
        "\n",
        "            'avg_neighbor_in_degree': np.mean(neighbor_in_degrees) if len(neighbor_in_degrees) > 0 else 0,\n",
        "            'min_neighbor_in_degree': np.min(neighbor_in_degrees) if len(neighbor_in_degrees) > 0 else 0,\n",
        "            'max_neighbor_in_degree': np.max(neighbor_in_degrees) if len(neighbor_in_degrees) > 0 else 0,\n",
        "            'sum_neighbor_in_degree': np.sum(neighbor_in_degrees),\n",
        "            'std_neighbor_in_degree': np.std(neighbor_in_degrees) if len(neighbor_in_degrees) > 0 else 0,\n",
        "            'ent_neighbor_in_degree': entropy(neighbor_in_degrees) if np.sum(neighbor_in_degrees) != 0 else 0,\n",
        "\n",
        "            'avg_neighbor_out_degree': np.mean(neighbor_out_degrees) if len(neighbor_out_degrees) > 0 else 0,\n",
        "            'min_neighbor_out_degree': np.min(neighbor_out_degrees) if len(neighbor_out_degrees) > 0 else 0,\n",
        "            'max_neighbor_out_degree': np.max(neighbor_out_degrees) if len(neighbor_out_degrees) > 0 else 0,\n",
        "            'sum_neighbor_out_degree': np.sum(neighbor_out_degrees),\n",
        "            'std_neighbor_out_degree': np.std(neighbor_out_degrees) if len(neighbor_out_degrees) > 0 else 0,\n",
        "            'ent_neighbor_out_degree': entropy(neighbor_out_degrees) if np.sum(neighbor_out_degrees) != 0 else 0,\n",
        "\n",
        "        }\n",
        "        return node_feature_dict\n",
        "\n",
        "    def gen_node_features_list(self, node_list):\n",
        "        \"\"\"\n",
        "        generate features for each node in the node_list\n",
        "        :param node_list: a list of different nodes\n",
        "        :return node_feature_df: a dataframe of the nodes and their features\n",
        "        \"\"\"\n",
        "        node_features_dict_list = [self.gen_node_features_single(node) for node in node_list]\n",
        "        node_feature_df = pd.DataFrame(node_features_dict_list, columns=self.node_feature_names)\n",
        "        return node_feature_df\n",
        "\n",
        "def main():\n",
        "    print('Read edge list and node list.')\n",
        "    edges_df = pd.read_csv(\"/content/drive/My Drive/BaselineToShow/edgeD1.csv\")\n",
        "    nodes_df = pd.read_csv(\"/content/drive/My Drive/BaselineToShow/nodeD1.csv\")\n",
        "    anchor_nodes = nodes_df['node'].tolist()\n",
        "\n",
        "    # --- generate features for all anchor nodes of a graph ---\n",
        "    print('Generate features for the anchor nodes.')\n",
        "    n_eng_features = NodeEngFeatures(nodes_df, edges_df)\n",
        "    node_feature_df = n_eng_features.gen_node_features_list(anchor_nodes)\n",
        "\n",
        "    # save anchor nodes features to file\n",
        "    print(node_feature_df.head())\n",
        "    print('Save node features dataframe.')\n",
        "    node_feature_df.to_csv(\"/content/drive/My Drive/BaselineToShow/featuresD1.csv\", index=False)\n",
        "    print(nodes_df['isp'].value_counts())\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read edge list and node list.\n",
            "Generate features for the anchor nodes.\n",
            "*** Original MD-Graph ***\n",
            "MultiDiGraph with 1403 nodes and 2999 edges\n",
            "                                         node  isp  degree  in_degree  \\\n",
            "0  0x51836a753e344257b361519e948ffcaf5fb8d521    0    1587          0   \n",
            "1  0x21f74c6bbc1e3ab9f0205e12de3a9daa14351aed    1     283        162   \n",
            "2  0xd089f4e1e39a9d9299d5762fc377c182c8a84a57    0       1          0   \n",
            "3  0x2be8055d8a3fc3191f39f21d6a3979aaf9ee8075    0       3          0   \n",
            "4  0x563b377a956c80d77a7c613a9343699ad6123911    0       3          0   \n",
            "\n",
            "   out_degree  avg_amount_in_tx  min_amount_in_tx  max_amount_in_tx  \\\n",
            "0        1587          0.000000             0.000               0.0   \n",
            "1         121          1.166167             0.001              30.0   \n",
            "2           1          0.000000             0.000               0.0   \n",
            "3           3          0.000000             0.000               0.0   \n",
            "4           3          0.000000             0.000               0.0   \n",
            "\n",
            "   sum_amount_in_tx  std_amount_in_tx  ...  max_neighbor_in_degree  \\\n",
            "0          0.000000          0.000000  ...                      76   \n",
            "1        188.919018          2.647542  ...                       5   \n",
            "2          0.000000          0.000000  ...                       1   \n",
            "3          0.000000          0.000000  ...                       3   \n",
            "4          0.000000          0.000000  ...                       2   \n",
            "\n",
            "   sum_neighbor_in_degree  std_neighbor_in_degree  ent_neighbor_in_degree  \\\n",
            "0                  1587.0                3.731792                6.259382   \n",
            "1                   121.0                0.539718                4.590285   \n",
            "2                     1.0                0.000000                0.000000   \n",
            "3                     3.0                0.000000                0.000000   \n",
            "4                     3.0                0.500000                0.636514   \n",
            "\n",
            "   avg_neighbor_out_degree  min_neighbor_out_degree  max_neighbor_out_degree  \\\n",
            "0                      0.0                        0                        0   \n",
            "1                      0.0                        0                        0   \n",
            "2                      0.0                        0                        0   \n",
            "3                      0.0                        0                        0   \n",
            "4                      0.0                        0                        0   \n",
            "\n",
            "   sum_neighbor_out_degree  std_neighbor_out_degree  ent_neighbor_out_degree  \n",
            "0                      0.0                      0.0                      0.0  \n",
            "1                      0.0                      0.0                      0.0  \n",
            "2                      0.0                      0.0                      0.0  \n",
            "3                      0.0                      0.0                      0.0  \n",
            "4                      0.0                      0.0                      0.0  \n",
            "\n",
            "[5 rows x 69 columns]\n",
            "Save node features dataframe.\n",
            "0    1380\n",
            "1      23\n",
            "Name: isp, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TUBVsk6imBNq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}