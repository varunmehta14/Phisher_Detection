{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08P0bJ7hC56T",
        "outputId": "67384f21-348b-4ba7-915d-9caaadd799df"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oQ-iCPSDEyR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import f1_score, precision_recall_fscore_support, accuracy_score, roc_auc_score\n",
        "from sklearn.manifold import TSNE\n",
        "import time\n",
        "import seaborn as sns\n",
        "\n",
        "rnd_seed = 42\n",
        "random.seed(rnd_seed)\n",
        "test_size = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlOLAd76Da-6"
      },
      "source": [
        "def perf_report(identifier, y_true, y_pred, binary, print_enable=False):\n",
        "    if binary:\n",
        "        # print(\">>> Binary Classification.\")\n",
        "        prec, rec, f1, num = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
        "        micro_f1 = f1_score(y_true, y_pred, average='binary')\n",
        "    else:\n",
        "        print(\">>> Multi-class Classification.\")\n",
        "        prec, rec, f1, num = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
        "        micro_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    if print_enable:\n",
        "        print(\"\\t*** {} performance reports: ***\".format(str(identifier)))\n",
        "        print(\"\\t\\tPrecision: %.3f \\n\\t\\tRecall: %.3f \\n\\t\\tF1-Score: %.3f\" % (prec, rec, f1))\n",
        "        print('\\t\\tMicro-Average F1-Score: %.3f' % micro_f1)\n",
        "        print('\\t\\tAccuracy: %.3f' % acc)\n",
        "        print(classification_report(y_true, y_pred))\n",
        "    return prec, rec, f1, acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI-pd8HVDfyG"
      },
      "source": [
        "def train_test_split(X, y, rnd_seed):\n",
        "    \"\"\"\n",
        "    split the features and the labels according to the indices\n",
        "    :param X: feature set, should be array or list\n",
        "    :param y: labels, should be array or list\n",
        "    :param rnd_seed: random seed\n",
        "    \"\"\"\n",
        "    # generate indices for the train and test set\n",
        "    indices = [i for i in range(len(y))]\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=rnd_seed)\n",
        "    sss.get_n_splits(indices, y)\n",
        "    train_indices, test_indices = next(sss.split(indices, y))\n",
        "\n",
        "    # train/test split\n",
        "    X_train = [X[i] for i in train_indices]\n",
        "    X_test = [X[i] for i in test_indices]\n",
        "\n",
        "    y_train = [y[i] for i in train_indices]\n",
        "    y_test = [y[i] for i in test_indices]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JLaR4pYDf5H"
      },
      "source": [
        "def simple_classification(clf, clf_id, emb_flag, X_train, X_test, y_train, y_test,\n",
        "                          binary, exp_id, print_enable=False):\n",
        "    \"\"\"\n",
        "    train the model on the train set and test it on the test set.\n",
        "    to be consistent among different run, the indices are passed.\n",
        "    important NOTE: it is implicitly inferred that the positive label is 1.\n",
        "    no cross-validation is applied.\n",
        "    \"\"\"\n",
        "\n",
        "    # train the model\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # predict the training set labels\n",
        "    y_train_pred = clf.predict(X_train)\n",
        "\n",
        "    # predict the test set labels\n",
        "    y_test_pred = clf.predict(X_test)\n",
        "\n",
        "    # evaluate the performance for the training set\n",
        "    tr_prec, tr_rec, tr_f1, tr_acc = perf_report(str(clf_id) + ' - Training Set',\n",
        "                                                 y_train, y_train_pred, binary, print_enable)\n",
        "    ts_prec, ts_rec, ts_f1, ts_acc = perf_report(str(clf_id) + ' - Test Set',\n",
        "                                                 y_test, y_test_pred, binary, print_enable)\n",
        "\n",
        "    # auc-roc\n",
        "    if binary:\n",
        "        y_test_proba = clf.predict_proba(X_test)[::,1]\n",
        "        y_train_proba = clf.predict_proba(X_train)[::,1]\n",
        "        tr_roc_auc = roc_auc_score(y_train, y_train_proba)\n",
        "        ts_roc_auc = roc_auc_score(y_test, y_test_proba)\n",
        "\n",
        "    split_exp_id = exp_id.split(\";\")\n",
        "    if len(split_exp_id) == 2:\n",
        "        index = split_exp_id[0]\n",
        "        id = split_exp_id[1]\n",
        "    elif len(split_exp_id) == 1:\n",
        "        index = 0\n",
        "        id = split_exp_id[0]\n",
        "    else:\n",
        "        raise ValueError(\"Incorrect Experiment ID!\")\n",
        "\n",
        "    perf_dict = {\n",
        "        'index': index,\n",
        "        'exp_id': id,\n",
        "        'emb_method': str(emb_flag),\n",
        "        'classifier': str(clf_id),\n",
        "\n",
        "        'train_prec': tr_prec,\n",
        "        'train_rec': tr_rec,\n",
        "        'train_f1': tr_f1,\n",
        "        'train_acc': tr_acc,\n",
        "        'train_auc': tr_roc_auc,\n",
        "\n",
        "        'test_prec': ts_prec,\n",
        "        'test_rec': ts_rec,\n",
        "        'test_f1': ts_f1,\n",
        "        'test_acc': ts_acc,\n",
        "        'test_auc': ts_roc_auc\n",
        "    }\n",
        "    print(perf_dict)\n",
        "    return perf_dict, clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBQI9W_XDmOA"
      },
      "source": [
        "def rf_lr_classification(X_train, X_test, y_train, y_test, stats_file, flag,\n",
        "                         binary, exp_id, print_report=False):\n",
        "    \"\"\"\n",
        "    apply classification to input X with label y with \"Random Forest\" & \"Logistic Regression\"\n",
        "    :param X_train: train set\n",
        "    :param X_test: test set\n",
        "    :param y_train: train set labels\n",
        "    :param y_test: test set labels\n",
        "    :param print_report: whether print the results of classification or not\n",
        "    :return the classification results\n",
        "    \"\"\"\n",
        "    # define classifier\n",
        "    rf_clf = RandomForestClassifier(n_estimators=50, max_features=10, max_depth=5, random_state=rnd_seed)\n",
        "    lr_clf = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1e5, random_state=rnd_seed)\n",
        "\n",
        "    # apply classification\n",
        "    rf_perf, rf_clf = simple_classification(rf_clf, 'RF', flag, X_train, X_test, y_train, y_test,\n",
        "                                            binary, exp_id, print_report)\n",
        "    lr_perf, lr_clf = simple_classification(lr_clf, 'LR', flag, X_train, X_test, y_train, y_test,\n",
        "                                            binary, exp_id, print_report)\n",
        "\n",
        "    # append the results to file\n",
        "    # stats_df = pd.read_csv(stats_file)\n",
        "    # stats_df = stats_df.append(rf_perf, ignore_index=True)\n",
        "    # stats_df = stats_df.append(lr_perf, ignore_index=True)\n",
        "    # stats_df.to_csv(stats_file, index=False)\n",
        "\n",
        "    return rf_perf, rf_clf, lr_perf, lr_clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58BmOhjuDz3A"
      },
      "source": [
        "def RF_sorted_feature_importance(clf, feature_name):\n",
        "    \"\"\"\n",
        "    return the top 10 most important features of the RF clf model\n",
        "    assumption: clf is a trained RF model\n",
        "    \"\"\"\n",
        "    # feature importance\n",
        "    importance = clf.feature_importances_\n",
        "    indices = np.argsort(importance)[::-1]\n",
        "\n",
        "    # Print the feature ranking\n",
        "    sorted_feature_name = [feature_name[indices[i]] for i in range(len(feature_name))]\n",
        "    sorted_feature_importance = [importance[indices[i]] for i in range(len(feature_name))]\n",
        "    feature_imp_df = pd.DataFrame(list(zip(sorted_feature_name, sorted_feature_importance)),\n",
        "                                  columns=['feature', 'importance'])\n",
        "    return feature_imp_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DVNFVSeD2-m"
      },
      "source": [
        "def RF_feature_imp(X, y, feature_name, png_file):\n",
        "    \"\"\"\n",
        "    calculate feature importance for the Random Forest Classifier\n",
        "    :param X: features\n",
        "    :param y: labels\n",
        "    :param feature_name: the name of the features\n",
        "    \"\"\"\n",
        "    # define and fit classifier\n",
        "    rf_clf = RandomForestClassifier(n_estimators=100, max_features=16, max_depth=5,\n",
        "                                    random_state=rnd_seed)\n",
        "    rf_clf.fit(X, y)\n",
        "\n",
        "    # feature importance\n",
        "    importances = rf_clf.feature_importances_\n",
        "    std = np.std([tree.feature_importances_ for tree in rf_clf.estimators_], axis=0)\n",
        "    indices = np.argsort(importances)[::-1]\n",
        "\n",
        "    # Print the feature ranking\n",
        "    print(\"Feature ranking:\")\n",
        "    for f in range(len(feature_name)):\n",
        "        print(\"%d. feature %d (%s) (%f)\" % (f + 1, indices[f], feature_name[indices[f]],\n",
        "                                            importances[indices[f]]))\n",
        "\n",
        "    # Plot the impurity-based feature importances of the forest\n",
        "    plt.figure()\n",
        "    plt.title(\"Feature Importance\")\n",
        "    plt.bar(range(len(feature_name)), importances[indices], color=\"g\", yerr=std[indices], align=\"center\")\n",
        "    plt.xticks(range(len(feature_name)), indices)\n",
        "    plt.xlim([-1, len(feature_name)])\n",
        "    # plt.show()\n",
        "    plt.savefig(png_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEarH8v0D3k1"
      },
      "source": [
        "def read_emb_and_node_list(emb_file, node_file):\n",
        "    # read embedding\n",
        "    emb_df = pd.read_csv(emb_file, sep=' ', skiprows=1, header=None)\n",
        "    emb_df.columns = ['node'] + [f'emb_{i}' for i in range(emb_df.shape[1] - 1)]\n",
        "\n",
        "    # read node list\n",
        "    node_df = pd.read_csv(node_file)\n",
        "    node_df = node_df[['node', 'isp']]\n",
        "\n",
        "    # merge\n",
        "    merged_df = emb_df.merge(node_df, on='node', how='left')\n",
        "\n",
        "    return merged_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ1I-sNqD7cW"
      },
      "source": [
        "def data_preproc_for_RiWalk_Binary_clf(emb_file, node_file):\n",
        "    \"\"\"\n",
        "    pre-process the RiWalk generated embedding for node classification\n",
        "    \"\"\"\n",
        "    # read and merge the data frames\n",
        "    merged_df = read_emb_and_node_list(emb_file, node_file)\n",
        "\n",
        "    # datasets for  BINARY classification\n",
        "    X = merged_df # only anchor nodes\n",
        "    y = X['isp'].tolist()\n",
        "    X = X.drop(['node', 'isp'], axis=1)\n",
        "    feature_names = X.columns\n",
        "    X = X.values.tolist()\n",
        "\n",
        "    # split the train and test set\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, rnd_seed)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, feature_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwpiriAHEB_f"
      },
      "source": [
        "def prepare_data_for_concat_fe_emb(emb_file, fe_file):\n",
        "    \"\"\"\n",
        "    pre-process the data for the node classification of a new dataset consisting of the\n",
        "    engineered features and the embeddings\n",
        "    \"\"\"\n",
        "    # read embedding\n",
        "    emb_df = pd.read_csv(emb_file, sep=' ', skiprows=1, header=None)\n",
        "    emb_df.columns = ['node'] + [f'emb_{i}' for i in range(emb_df.shape[1] - 1)]\n",
        "\n",
        "    # read node list\n",
        "    node_df = pd.read_csv(fe_file)\n",
        "    # scale features\n",
        "    feature_col = [f for f in node_df.columns if f not in ['node', 'isp']]\n",
        "    scaler = StandardScaler()\n",
        "    node_df[feature_col] = scaler.fit_transform(node_df[feature_col])\n",
        "\n",
        "    # merge\n",
        "    merged_df = emb_df.merge(node_df, on='node', how='left')\n",
        "\n",
        "    # datasets for  BINARY classification\n",
        "    X = merged_df  # only anchor nodes\n",
        "    y = X['isp'].tolist()\n",
        "    X = X.drop(['node', 'isp'], axis=1)\n",
        "    X = X.values.tolist()\n",
        "\n",
        "    # split the train and test set\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, rnd_seed)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGsQ_hUmECB2"
      },
      "source": [
        "def plot_TSNE(values, labels, png_file):\n",
        "    \"\"\"\n",
        "    plot the embeddings as a TSNE graph\n",
        "    \"\"\"\n",
        "    print('\\tt-SNE starts.')\n",
        "    time_start = time.time()\n",
        "    tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
        "    tsne_results = tsne.fit_transform(values)\n",
        "    print('\\tt-SNE done! Time elapsed: {} seconds'.format(time.time() - time_start))\n",
        "\n",
        "    # plotting\n",
        "    p_data = {'tsne-2d-first': tsne_results[:, 0],\n",
        "              'tsne-2d-second': tsne_results[:, 1],\n",
        "              'label': labels,\n",
        "              }\n",
        "\n",
        "    plt.figure(figsize=(16, 10))\n",
        "    sns.scatterplot(\n",
        "        x=\"tsne-2d-first\", y=\"tsne-2d-second\",\n",
        "        hue=\"label\",\n",
        "        palette=sns.color_palette(\"hls\", len(set(labels))),\n",
        "        data=p_data,\n",
        "        legend=\"full\",\n",
        "        alpha=0.3\n",
        "    )\n",
        "    # plt.show()\n",
        "    plt.savefig(png_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hjjnAPQECEa"
      },
      "source": [
        "def EF_analysis_selected_nodes(output_path, graph, edges_filename, nodes_filename,\n",
        "                               features_filename, stats_file, feat_imp_filename,\n",
        "                               flag, binary, rnd_seed, exp_id, extra_analysis):\n",
        "    # print(\"\\tRead edge list and node list.\")\n",
        "    # start_time = time.time()\n",
        "    # edges_df = pd.read_csv(edges_filename)\n",
        "    nodes_df = pd.read_csv(nodes_filename)\n",
        "    # print(\"\\t\\tTime elapsed {} seconds.\".format(time.time() - start_time))\n",
        "\n",
        "    print(\"\\tRetrieve anchor nodes for classification.\")\n",
        "    start_time = time.time()\n",
        "    selected_node_list = nodes_df['node'].tolist()\n",
        "    print(\"\\t\\tTime elapsed {} seconds.\".format(time.time() - start_time))\n",
        "\n",
        "\n",
        "    print(\"\\tRead features for anchor nodes.\")\n",
        "    start_time = time.time()\n",
        "    all_node_features_df = pd.read_csv(features_filename)\n",
        "    features_df = all_node_features_df.loc[all_node_features_df['node'].isin(selected_node_list)]\n",
        "    print(\"\\t\\tTime elapsed {} seconds.\".format(time.time() - start_time))\n",
        "\n",
        "    # make ready for classification\n",
        "    # features_df = pd.read_csv(features_filename)\n",
        "    y = features_df['isp'].tolist()  # only anchor nodes where selected\n",
        "    X_orig = features_df.drop(['node', 'isp'], axis=1)\n",
        "    feature_names = X_orig.columns\n",
        "    X_orig = X_orig.values.tolist()\n",
        "\n",
        "    # split the train and test set\n",
        "    print(\"\\tTrain-Test split.\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_orig, y, rnd_seed)\n",
        "\n",
        "    # scale the features; note that it should be fitted on the train set ONLY\n",
        "    print('\\tScaling the features.')\n",
        "    min_max_scaler = MinMaxScaler()\n",
        "    min_max_scaler.fit(X_train)\n",
        "    X_train_scaled = min_max_scaler.transform(X_train)\n",
        "    X_test_scaled = min_max_scaler.transform(X_test)\n",
        "\n",
        "    # classification\n",
        "    print('\\tApplying classification.')\n",
        "    start_time = time.time()\n",
        "    rf_perf, rf_clf, lr_perf, lr_clf = rf_lr_classification(X_train_scaled, X_test_scaled, y_train,\n",
        "                                                            y_test, stats_file, flag, binary,\n",
        "                                                            exp_id, print_report=True)\n",
        "    print(\"\\t\\tTime elapsed {} seconds.\".format(time.time() - start_time))\n",
        "\n",
        "    # calculates and saves features importance\n",
        "    feature_imp_df = RF_sorted_feature_importance(rf_clf, feature_names)\n",
        "    feature_imp_df.to_csv(feat_imp_filename, index=False)\n",
        "\n",
        "    if extra_analysis:\n",
        "        # Feature importance\n",
        "        print(\"\\tInvestigate feature importance.\")\n",
        "        png_file = output_path + '/' + graph + '_' + flag + '_FE_feature_impo.png'\n",
        "        RF_feature_imp(X_train_scaled, y_train, feature_names, png_file)\n",
        "\n",
        "        # plot t-SNE graph\n",
        "        print(\"\\tt-SNE graph.\")\n",
        "        values = X_orig\n",
        "        groups = y\n",
        "        png_file = output_path + '/' + graph + '_' + flag + '_FE_tsne.png'\n",
        "        plot_TSNE(values, groups, png_file)\n",
        "\n",
        "    print(\"FE node classification finished.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g71bgI2RECGZ"
      },
      "source": [
        "def RiWalk_analysis_selected_nodes(output_path, graph, emb_filename, nodes_filename, stats_filename,\n",
        "                                   flag, binary, exp_id, extra_analysis):\n",
        "    # prepare the data\n",
        "    print(\"\\tPrepare data sets.\")\n",
        "    X_train, X_test, y_train, y_test, feature_names = data_preproc_for_RiWalk_Binary_clf(emb_filename,\n",
        "                                                                                         nodes_filename)\n",
        "    # classification\n",
        "    print('\\tApplying classification.')\n",
        "    start_time = time.time()\n",
        "    rf_lr_classification(X_train, X_test, y_train, y_test, stats_filename, flag,\n",
        "                         binary, exp_id, print_report=True)\n",
        "    print(\"\\tTime elapsed {} seconds.\".format(time.time() - start_time))\n",
        "\n",
        "    if extra_analysis:\n",
        "        # Feature importance\n",
        "        print(\"\\tInvestigate feature importance.\")\n",
        "        png_file = output_path + '/' + graph + '_' + flag + '_Ri_feature_impo.png'\n",
        "        RF_feature_imp(X_train, y_train, feature_names, png_file)\n",
        "\n",
        "        # plot t-SNE graph\n",
        "        print(\"\\tPlot t-SNE.\")\n",
        "        values = X_train + X_test\n",
        "        groups = y_train + y_test\n",
        "        # nodes_df = pd.read_csv(nodes_filename)\n",
        "        png_file = output_path + '/' + graph + flag + '_Ri_tsne.png'\n",
        "        plot_TSNE(values, groups, png_file)\n",
        "\n",
        "    print(\"RiWalk node classification finished.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6eKe6V3ECIk"
      },
      "source": [
        "def nd_clf_fe_emb_combined(emb_file, fe_file, stats_file, flag, binary, exp_id):\n",
        "    \"\"\"\n",
        "    apply the node classification based on a new feature set constructed by combining the\n",
        "    engineered features and the (structural) embedding generated by an automatic method like node2vec\n",
        "    \"\"\"\n",
        "    print(\"\\tConcatenating embedding with engineered features for node classification.\")\n",
        "    # data preparation\n",
        "    X_train, X_test, y_train, y_test = prepare_data_for_concat_fe_emb(emb_file, fe_file)\n",
        "\n",
        "    # classification\n",
        "    print('\\tApplying classification.')\n",
        "    start_time = time.time()\n",
        "    rf_lr_classification(X_train, X_test, y_train, y_test, stats_file, flag,\n",
        "                         binary, exp_id, print_report=True)\n",
        "    print(\"\\tTime elapsed {} seconds.\".format(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU2svQ8GECKj",
        "outputId": "ab1cd0f1-15f2-4cac-e086-335893359c02"
      },
      "source": [
        "def main():\n",
        "    binary = True\n",
        "\n",
        "    # args = ArgParser.parse_args()\n",
        "    # input_path = args.input\n",
        "    # graph_filename = args.graph\n",
        "    # prod_data_dir = args.output\n",
        "\n",
        "    # flag = args.flag\n",
        "    # clf_opt = args.clf_opt\n",
        "    # exp_id = args.exp_id\n",
        "    flag = 'sp'\n",
        "    clf_opt = 'concat'\n",
        "    exp_id = '1;elliptic'\n",
        "\n",
        "    # data_path = main_path + 'inputs/'\n",
        "    # prod_data_dir = main_path + 'outputs/'\n",
        "    # stats_file = prod_data_dir + 'stats_' + flag + '.csv'\n",
        "\n",
        "    # edges_filename = input_path + 'edges_' + graph_filename + '.csv'\n",
        "    # nodes_filename = input_path + 'nodes_' + graph_filename + '.csv'\n",
        "    # features_filename = prod_data_dir + 'features_' + graph_filename + '.csv'\n",
        "    nodes_filename = \"/content/drive/My Drive/BaselineToShow/nodeD1.csv\"\n",
        "    edges_filename = \"/content/drive/My Drive/BaselineToShow/edgeD1.csv\"\n",
        "    features_filename = \"/content/drive/My Drive/BaselineToShow/featuresD1.csv\"\n",
        "    feat_imp_filename = \"/content/drive/My Drive/BaselineToShow/imp_featuresD1.csv\"\n",
        "    prod_data_dir = \"/content/drive/My Drive/BaselineToShow/\"\n",
        "    graph_filename = 'graph_filename'\n",
        "    stats_file = \"/content/drive/My Drive/BaselineToShow/stats_SIGTRAN.csv\"\n",
        "\n",
        "    # feat_imp_filename = prod_data_dir + 'feature_importance_' + graph_filename + '.csv'\n",
        "\n",
        "    # if clf_opt == 'fe':\n",
        "    #     # ------------------ Feature Engineering ------------------\n",
        "    #     # read the input file and generating the features and the labels set\n",
        "    #     print(\"Node Classification --- Feature Engineering ---\")\n",
        "\n",
        "    #     EF_analysis_selected_nodes(prod_data_dir, graph_filename, edges_filename, nodes_filename,\n",
        "    #                                features_filename, stats_file, feat_imp_filename, 'FE', binary,\n",
        "    #                                rnd_seed, exp_id, extra_analysis=False)\n",
        "    #     print(\"--- Node Classification Feature Engineering is done ---\")\n",
        "        # ---------------------------------------------------------\n",
        "\n",
        "    if clf_opt == 'concat':\n",
        "        print(\"Node classification: Concat. FE &\" + flag + \" embeddings.\")\n",
        "\n",
        "        emb_file = '/content/drive/My Drive/BaselineToShow/embeddings.emb'\n",
        "        df1 = pd.read_csv(feat_imp_filename)\n",
        "        imp_features = list(df1['feature'][0:10])\n",
        "        df2 = pd.read_csv(features_filename)\n",
        "        imp_features.insert(0, 'isp')\n",
        "        imp_features.insert(0, 'node')\n",
        "        df_final = df2[imp_features]\n",
        "        df_final.to_csv('/content/drive/My Drive/BaselineToShow/SIGTRANtop10D1.csv')\n",
        "        fe_file = '/content/drive/My Drive/BaselineToShow/SIGTRANtop10D1.csv'\n",
        "        nd_clf_fe_emb_combined(emb_file, fe_file, stats_file, flag, binary, exp_id)\n",
        "\n",
        "    # else:\n",
        "    #     # ------------------ RiWalk -------------------------------\n",
        "    #     print(\"Node classification: --- RiWalk - \" + flag + \"---\")\n",
        "\n",
        "    #     # set file names\n",
        "    #     emb_filename = prod_data_dir + 'emb_' + str(flag) + '_' + graph_filename + '.emb'\n",
        "\n",
        "    #     RiWalk_analysis_selected_nodes(prod_data_dir, graph_filename, emb_filename, nodes_filename, stats_file,\n",
        "    #                                    flag, binary, exp_id, extra_analysis=False)\n",
        "    #     print(\"--- Classification RiWalk is done ---\")\n",
        "    #     # ---------------------------------------------------------\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node classification: Concat. FE &sp embeddings.\n",
            "\tConcatenating embedding with engineered features for node classification.\n",
            "\tApplying classification.\n",
            "\t*** RF - Training Set performance reports: ***\n",
            "\t\tPrecision: 1.000 \n",
            "\t\tRecall: 0.944 \n",
            "\t\tF1-Score: 0.971\n",
            "\t\tMicro-Average F1-Score: 0.971\n",
            "\t\tAccuracy: 0.999\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1104\n",
            "           1       1.00      0.94      0.97        18\n",
            "\n",
            "    accuracy                           1.00      1122\n",
            "   macro avg       1.00      0.97      0.99      1122\n",
            "weighted avg       1.00      1.00      1.00      1122\n",
            "\n",
            "\t*** RF - Test Set performance reports: ***\n",
            "\t\tPrecision: 0.800 \n",
            "\t\tRecall: 0.800 \n",
            "\t\tF1-Score: 0.800\n",
            "\t\tMicro-Average F1-Score: 0.800\n",
            "\t\tAccuracy: 0.993\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       276\n",
            "           1       0.80      0.80      0.80         5\n",
            "\n",
            "    accuracy                           0.99       281\n",
            "   macro avg       0.90      0.90      0.90       281\n",
            "weighted avg       0.99      0.99      0.99       281\n",
            "\n",
            "{'index': '1', 'exp_id': 'elliptic', 'emb_method': 'sp', 'classifier': 'RF', 'train_prec': 1.0, 'train_rec': 0.9444444444444444, 'train_f1': 0.9714285714285714, 'train_acc': 0.9991087344028521, 'train_auc': 0.9999999999999999, 'test_prec': 0.8, 'test_rec': 0.8, 'test_f1': 0.8000000000000002, 'test_acc': 0.9928825622775801, 'test_auc': 0.942391304347826}\n",
            "\t*** LR - Training Set performance reports: ***\n",
            "\t\tPrecision: 1.000 \n",
            "\t\tRecall: 0.667 \n",
            "\t\tF1-Score: 0.800\n",
            "\t\tMicro-Average F1-Score: 0.800\n",
            "\t\tAccuracy: 0.995\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      1104\n",
            "           1       1.00      0.67      0.80        18\n",
            "\n",
            "    accuracy                           0.99      1122\n",
            "   macro avg       1.00      0.83      0.90      1122\n",
            "weighted avg       0.99      0.99      0.99      1122\n",
            "\n",
            "\t*** LR - Test Set performance reports: ***\n",
            "\t\tPrecision: 0.800 \n",
            "\t\tRecall: 0.800 \n",
            "\t\tF1-Score: 0.800\n",
            "\t\tMicro-Average F1-Score: 0.800\n",
            "\t\tAccuracy: 0.993\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       276\n",
            "           1       0.80      0.80      0.80         5\n",
            "\n",
            "    accuracy                           0.99       281\n",
            "   macro avg       0.90      0.90      0.90       281\n",
            "weighted avg       0.99      0.99      0.99       281\n",
            "\n",
            "{'index': '1', 'exp_id': 'elliptic', 'emb_method': 'sp', 'classifier': 'LR', 'train_prec': 1.0, 'train_rec': 0.6666666666666666, 'train_f1': 0.8, 'train_acc': 0.9946524064171123, 'train_auc': 0.9400161030595814, 'test_prec': 0.8, 'test_rec': 0.8, 'test_f1': 0.8000000000000002, 'test_acc': 0.9928825622775801, 'test_auc': 0.8072463768115943}\n",
            "\tTime elapsed 0.790785551071167 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cy6yxtW3Bi-s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}