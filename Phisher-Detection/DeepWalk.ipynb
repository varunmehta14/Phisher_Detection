{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV9hZlZEH0Xx",
        "outputId": "e929f96a-fe20-444b-e616-de8183c23331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "JLfhwkaBGWcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "import networkx as nx\n",
        "from tqdm import tqdm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import OneClassSVM, SVC\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import f1_score, precision_recall_fscore_support, accuracy_score, roc_auc_score\n",
        "from sklearn.manifold import TSNE\n",
        "import time\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from gensim.models import Word2Vec\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "rnd_seed = 42\n",
        "random.seed(rnd_seed)\n",
        "test_size = 0.2"
      ],
      "metadata": {
        "id": "KUJBiK6KF61X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Paths"
      ],
      "metadata": {
        "id": "CCx7oX6vHncN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_data = '‘/content/drive/My Drive/BaselineToShow/D1.csv’'\n",
        "edge_list_file_name = '/content/drive/My Drive/BaselineToShow/edgelist.edgelist'\n",
        "node_list_file_name = \"/content/drive/My Drive/BaselineToShow/nodeD1.csv\"\n",
        "edge_filename = \"/content/drive/My Drive/BaselineToShow/edgeD1.csv\"\n",
        "stats_file = '/content/drive/My Drive/BaselineToShow/deepwalk/stats.csv'\n",
        "embeddings_filename = '/content/drive/My Drive/BaselineToShow/embeddings.emb'"
      ],
      "metadata": {
        "id": "nTD3012nGfUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Graph"
      ],
      "metadata": {
        "id": "Vwlg0TJgOuzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nx_g = nx.from_pandas_edgelist(pd.read_csv(edge_list_file_name), source='source', target='target',\n",
        "                                   create_using=nx.DiGraph())\n",
        "print(\"Graph info:\", nx.info(nx_g))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIEOvbdTHoxI",
        "outputId": "c341be98-1a4e-4c0b-e5dd-9bd0cb8838aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph info: DiGraph with 1403 nodes and 1504 edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DeepWalk and Creating Embeddings"
      ],
      "metadata": {
        "id": "zRG8K-stPvBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 10\n",
        "walk_per_node = 5\n",
        "walk_length = 10\n",
        "\n",
        "def get_randomwalk(node, path_length):\n",
        "    random_walk = [node]\n",
        "    for i in range(path_length-1):\n",
        "        temp = list(nx_g.neighbors(node))\n",
        "        temp = list(set(temp) - set(random_walk))    \n",
        "        if len(temp) == 0:\n",
        "            break\n",
        "\n",
        "        random_node = random.choice(temp)\n",
        "        random_walk.append(random_node)\n",
        "        node = random_node\n",
        "    return random_walk\n",
        "\n",
        "all_nodes = list(nx_g.nodes())\n",
        "random_walks = []\n",
        "for n in tqdm(all_nodes):\n",
        "    for i in range(walk_per_node):\n",
        "        random_walks.append(get_randomwalk(n,walk_length))\n",
        "\n",
        "model = Word2Vec(window = 4, sg = 1, hs = 0, negative = 10, alpha=0.03, min_alpha=0.0007, seed = 14)\n",
        "model.build_vocab(random_walks, progress_per=2)\n",
        "model.train(random_walks, total_examples = model.corpus_count, epochs=20, report_delay=1)\n",
        "\n",
        "model.wv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJJZWmIYHu60",
        "outputId": "48001b94-62bf-4ce6-e3bb-6128931061f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1403/1403 [00:00<00:00, 57148.77it/s]\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7faabd2a48d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Displaying Classification Report Function"
      ],
      "metadata": {
        "id": "lbUfvV10P-TL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perf_report(identifier, y_true, y_pred, binary, print_enable=False):\n",
        "    if binary:\n",
        "        print(\">>> Binary Classification.\")\n",
        "        prec, rec, f1, num = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
        "        micro_f1 = f1_score(y_true, y_pred, average='binary')\n",
        "    else:\n",
        "        print(\">>> Multi-class Classification.\")\n",
        "        prec, rec, f1, num = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
        "        micro_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    if print_enable:\n",
        "        print(\"\\t*** {} performance reports: ***\".format(str(identifier)))\n",
        "        print(\"\\t\\tPrecision: %.3f \\n\\t\\tRecall: %.3f \\n\\t\\tF1-Score: %.3f\" % (prec, rec, f1))\n",
        "        print('\\t\\tMicro-Average F1-Score: %.3f' % micro_f1)\n",
        "        print('\\t\\tAccuracy: %.3f' % acc)\n",
        "        print(classification_report(y_true, y_pred))\n",
        "    return prec, rec, f1, acc"
      ],
      "metadata": {
        "id": "QdQXHWViNOdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spliting Data Into Train and Test"
      ],
      "metadata": {
        "id": "qnoYn81BQDXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(X, y, rnd_seed):\n",
        "\n",
        "    # generate indices for the train and test set\n",
        "    indices = [i for i in range(len(y))]\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=rnd_seed)\n",
        "    sss.get_n_splits(indices, y)\n",
        "    train_indices, test_indices = next(sss.split(indices, y))\n",
        "\n",
        "    # train/test split\n",
        "    X_train = [X[i] for i in train_indices]\n",
        "    X_test = [X[i] for i in test_indices]\n",
        "\n",
        "    y_train = [y[i] for i in train_indices]\n",
        "    y_test = [y[i] for i in test_indices]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "kjJ4bNWeNPAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function To Fit Models and Get Metrics"
      ],
      "metadata": {
        "id": "imYaBJwUQ6Gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_classification(clf, clf_id, emb_flag, X_train, X_test, y_train, y_test,\n",
        "                          binary, exp_id, print_enable=False):\n",
        "\n",
        "    # train the model\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # predict the training set labels\n",
        "    y_train_pred = clf.predict(X_train)\n",
        "\n",
        "    # predict the test set labels\n",
        "    y_test_pred = clf.predict(X_test)\n",
        "\n",
        "    # evaluate the performance for the training set\n",
        "    tr_prec, tr_rec, tr_f1, tr_acc = perf_report(str(clf_id) + ' - Training Set', y_train, y_train_pred, binary, print_enable)\n",
        "    ts_prec, ts_rec, ts_f1, ts_acc = perf_report(str(clf_id) + ' - Test Set', y_test, y_test_pred, binary, print_enable)\n",
        "\n",
        "    # auc-roc\n",
        "    if binary:\n",
        "        y_test_proba = clf.predict_proba(X_test)[::,1]\n",
        "        y_train_proba = clf.predict_proba(X_train)[::,1]\n",
        "        tr_roc_auc = roc_auc_score(y_train, y_train_proba)\n",
        "        ts_roc_auc = roc_auc_score(y_test, y_test_proba)\n",
        "\n",
        "    split_exp_id = exp_id.split(\";\")\n",
        "    if len(split_exp_id) == 2:\n",
        "        index = split_exp_id[0]\n",
        "        id = split_exp_id[1]\n",
        "    elif len(split_exp_id) == 1:\n",
        "        index = 0\n",
        "        id = split_exp_id[0]\n",
        "    else:\n",
        "        raise ValueError(\"Incorrect Experiment ID!\")\n",
        "\n",
        "    perf_dict = {\n",
        "        'index': index,\n",
        "        'exp_id': id,\n",
        "        'emb_method': str(emb_flag),\n",
        "        'classifier': str(clf_id),\n",
        "\n",
        "        'train_prec': tr_prec,\n",
        "        'train_rec': tr_rec,\n",
        "        'train_f1': tr_f1,\n",
        "        'train_acc': tr_acc,\n",
        "        'train_auc': tr_roc_auc,\n",
        "\n",
        "        'test_prec': ts_prec,\n",
        "        'test_rec': ts_rec,\n",
        "        'test_f1': ts_f1,\n",
        "        'test_acc': ts_acc,\n",
        "        'test_auc': ts_roc_auc\n",
        "    }\n",
        "\n",
        "    return perf_dict, clf"
      ],
      "metadata": {
        "id": "vRFUudUYQzmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Classification Function"
      ],
      "metadata": {
        "id": "tW3wKfHUQMj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rf_lr_classification(X_train, X_test, y_train, y_test, stats_file, flag,\n",
        "                         binary, exp_id, print_report=False):\n",
        "    rf_clf = RandomForestClassifier(n_estimators=50, max_features=10, max_depth=5, random_state=rnd_seed)\n",
        "    lr_clf = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1e5, random_state=rnd_seed)\n",
        "\n",
        "    rf_perf, rf_clf = simple_classification(rf_clf, 'Random Forest', flag, X_train, X_test, y_train, y_test,\n",
        "                                            binary, exp_id, print_report)\n",
        "    binary = True\n",
        "    lr_perf, lr_clf = simple_classification(lr_clf, 'Logistic Regression', flag, X_train, X_test, y_train, y_test,\n",
        "                                            binary, exp_id, print_report)\n",
        "\n",
        "    return rf_perf, rf_clf, lr_perf, lr_clf"
      ],
      "metadata": {
        "id": "YEJyJz25NQ7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main"
      ],
      "metadata": {
        "id": "uMhMXuuIQUsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nodes_df = pd.read_csv(node_list_file_name)\n",
        "anchor_nodes_df = nodes_df\n",
        "node_list = [str(node_id) for node_id in anchor_nodes_df['node'].tolist()]\n",
        "embeddings = [model.wv.get_vector(node) for node in node_list]\n",
        "model.wv.save_word2vec_format(embeddings_filename)\n",
        "labels = anchor_nodes_df['isp'].tolist()\n",
        "\n",
        "rnd_seed = 42\n",
        "binary = True\n",
        "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, rnd_seed)\n",
        "rf_lr_classification(X_train, X_test, y_train, y_test, stats_file, 'deepwalk', binary, '1;elliptic' , print_report=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gpo7J6f2MWVW",
        "outputId": "2c7e19d9-49a4-4e40-bdd2-17a6fca3bf0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Binary Classification.\n",
            "\t*** Random Forest - Training Set performance reports: ***\n",
            "\t\tPrecision: 1.000 \n",
            "\t\tRecall: 0.722 \n",
            "\t\tF1-Score: 0.839\n",
            "\t\tMicro-Average F1-Score: 0.839\n",
            "\t\tAccuracy: 0.996\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1104\n",
            "           1       1.00      0.72      0.84        18\n",
            "\n",
            "    accuracy                           1.00      1122\n",
            "   macro avg       1.00      0.86      0.92      1122\n",
            "weighted avg       1.00      1.00      1.00      1122\n",
            "\n",
            ">>> Binary Classification.\n",
            "\t*** Random Forest - Test Set performance reports: ***\n",
            "\t\tPrecision: 1.000 \n",
            "\t\tRecall: 0.200 \n",
            "\t\tF1-Score: 0.333\n",
            "\t\tMicro-Average F1-Score: 0.333\n",
            "\t\tAccuracy: 0.986\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       276\n",
            "           1       1.00      0.20      0.33         5\n",
            "\n",
            "    accuracy                           0.99       281\n",
            "   macro avg       0.99      0.60      0.66       281\n",
            "weighted avg       0.99      0.99      0.98       281\n",
            "\n",
            ">>> Binary Classification.\n",
            "\t*** Logistic Regression - Training Set performance reports: ***\n",
            "\t\tPrecision: 1.000 \n",
            "\t\tRecall: 0.056 \n",
            "\t\tF1-Score: 0.105\n",
            "\t\tMicro-Average F1-Score: 0.105\n",
            "\t\tAccuracy: 0.985\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      1104\n",
            "           1       1.00      0.06      0.11        18\n",
            "\n",
            "    accuracy                           0.98      1122\n",
            "   macro avg       0.99      0.53      0.55      1122\n",
            "weighted avg       0.99      0.98      0.98      1122\n",
            "\n",
            ">>> Binary Classification.\n",
            "\t*** Logistic Regression - Test Set performance reports: ***\n",
            "\t\tPrecision: 0.000 \n",
            "\t\tRecall: 0.000 \n",
            "\t\tF1-Score: 0.000\n",
            "\t\tMicro-Average F1-Score: 0.000\n",
            "\t\tAccuracy: 0.982\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       276\n",
            "           1       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.98       281\n",
            "   macro avg       0.49      0.50      0.50       281\n",
            "weighted avg       0.96      0.98      0.97       281\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'index': '1',\n",
              "  'exp_id': 'elliptic',\n",
              "  'emb_method': 'deepwalk',\n",
              "  'classifier': 'Random Forest',\n",
              "  'train_prec': 1.0,\n",
              "  'train_rec': 0.7222222222222222,\n",
              "  'train_f1': 0.8387096774193548,\n",
              "  'train_acc': 0.9955436720142602,\n",
              "  'train_auc': 0.9999496779388084,\n",
              "  'test_prec': 1.0,\n",
              "  'test_rec': 0.2,\n",
              "  'test_f1': 0.33333333333333337,\n",
              "  'test_acc': 0.9857651245551602,\n",
              "  'test_auc': 0.9347826086956523},\n",
              " RandomForestClassifier(max_depth=5, max_features=10, n_estimators=50,\n",
              "                        random_state=42),\n",
              " {'index': '1',\n",
              "  'exp_id': 'elliptic',\n",
              "  'emb_method': 'deepwalk',\n",
              "  'classifier': 'Logistic Regression',\n",
              "  'train_prec': 1.0,\n",
              "  'train_rec': 0.05555555555555555,\n",
              "  'train_f1': 0.10526315789473684,\n",
              "  'train_acc': 0.9848484848484849,\n",
              "  'train_auc': 0.9422302737520128,\n",
              "  'test_prec': 0.0,\n",
              "  'test_rec': 0.0,\n",
              "  'test_f1': 0.0,\n",
              "  'test_acc': 0.9822064056939501,\n",
              "  'test_auc': 0.9572463768115942},\n",
              " LogisticRegression(max_iter=100000.0, penalty='l1', random_state=42,\n",
              "                    solver='liblinear'))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}